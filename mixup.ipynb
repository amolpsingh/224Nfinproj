{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2a14343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt, style; style.use('fivethirtyeight')\n",
    "import seaborn as sns; sns.set(context='talk')\n",
    "\n",
    "from IPython.display import display, HTML, IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209c59c",
   "metadata": {},
   "source": [
    "Dataset Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a776b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>50%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>4587.500000</td>\n",
       "      <td>2648.450018</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4587.5</td>\n",
       "      <td>9174.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>20.810431</td>\n",
       "      <td>2.307676</td>\n",
       "      <td>15.30</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2016.715095</td>\n",
       "      <td>1.979656</td>\n",
       "      <td>2013.00</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2019.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eta</th>\n",
       "      <td>2018.802799</td>\n",
       "      <td>2.422862</td>\n",
       "      <td>2013.00</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2025.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arm</th>\n",
       "      <td>53.824127</td>\n",
       "      <td>6.897962</td>\n",
       "      <td>30.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Changeup</th>\n",
       "      <td>49.858290</td>\n",
       "      <td>5.364976</td>\n",
       "      <td>30.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control</th>\n",
       "      <td>49.205290</td>\n",
       "      <td>5.059892</td>\n",
       "      <td>30.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Curveball</th>\n",
       "      <td>52.929583</td>\n",
       "      <td>5.675287</td>\n",
       "      <td>35.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cutter</th>\n",
       "      <td>52.475000</td>\n",
       "      <td>4.936723</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fastball</th>\n",
       "      <td>59.531873</td>\n",
       "      <td>6.665786</td>\n",
       "      <td>40.00</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Field</th>\n",
       "      <td>51.633871</td>\n",
       "      <td>5.503923</td>\n",
       "      <td>30.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hit</th>\n",
       "      <td>49.681105</td>\n",
       "      <td>5.510597</td>\n",
       "      <td>30.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Power</th>\n",
       "      <td>47.932818</td>\n",
       "      <td>9.420963</td>\n",
       "      <td>20.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run</th>\n",
       "      <td>48.837240</td>\n",
       "      <td>12.169090</td>\n",
       "      <td>20.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slider</th>\n",
       "      <td>52.735618</td>\n",
       "      <td>5.121491</td>\n",
       "      <td>30.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Splitter</th>\n",
       "      <td>53.333333</td>\n",
       "      <td>7.637626</td>\n",
       "      <td>40.00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>70.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlb_played_first</th>\n",
       "      <td>2017.065463</td>\n",
       "      <td>1.735580</td>\n",
       "      <td>2010.00</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2019.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debut_age</th>\n",
       "      <td>23.374194</td>\n",
       "      <td>1.558851</td>\n",
       "      <td>18.89</td>\n",
       "      <td>23.4</td>\n",
       "      <td>29.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0.078147</td>\n",
       "      <td>0.613681</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean          std      min     50%      max\n",
       "Unnamed: 0        4587.500000  2648.450018     1.00  4587.5  9174.00\n",
       "age                 20.810431     2.307676    15.30    21.0    31.90\n",
       "year              2016.715095     1.979656  2013.00  2017.0  2019.00\n",
       "eta               2018.802799     2.422862  2013.00  2019.0  2025.00\n",
       "Arm                 53.824127     6.897962    30.00    55.0    80.00\n",
       "Changeup            49.858290     5.364976    30.00    50.0    70.00\n",
       "Control             49.205290     5.059892    30.00    50.0    70.00\n",
       "Curveball           52.929583     5.675287    35.00    55.0    70.00\n",
       "Cutter              52.475000     4.936723    40.00    50.0    70.00\n",
       "Fastball            59.531873     6.665786    40.00    60.0    80.00\n",
       "Field               51.633871     5.503923    30.00    50.0    80.00\n",
       "Hit                 49.681105     5.510597    30.00    50.0    80.00\n",
       "Power               47.932818     9.420963    20.00    50.0    80.00\n",
       "Run                 48.837240    12.169090    20.00    50.0    80.00\n",
       "Slider              52.735618     5.121491    30.00    50.0    70.00\n",
       "Splitter            53.333333     7.637626    40.00    50.0    70.00\n",
       "mlb_played_first  2017.065463     1.735580  2010.00  2017.0  2019.00\n",
       "debut_age           23.374194     1.558851    18.89    23.4    29.27\n",
       "label                0.078147     0.613681    -1.00     0.0     1.00"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/twtc.csv')\n",
    "\n",
    "df_label_mask = (df.drop(columns='label') == 0).assign(label=False)\n",
    "df = df.mask(df_label_mask)\n",
    "\n",
    "df.describe().T[['mean', 'std', 'min', '50%', 'max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c75d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-1.18.3-py3-none-any.whl (311 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.1-cp39-cp39-macosx_10_9_x86_64.whl (574 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pyarrow!=4.0.0,>=3.0.0\n",
      "  Using cached pyarrow-7.0.0-cp39-cp39-macosx_10_13_x86_64.whl (20.2 MB)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from datasets) (4.62.3)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.0.0-cp39-cp39-macosx_10_9_x86_64.whl (34 kB)\n",
      "Requirement already satisfied: pandas in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2021.8.1)\n",
      "Requirement already satisfied: packaging in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from datasets) (21.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from datasets) (2.26.0)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.12.2-py39-none-any.whl (128 kB)\n",
      "Requirement already satisfied: pyyaml in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl (28 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.7.2-cp39-cp39-macosx_10_9_x86_64.whl (121 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl (36 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/eishmaheshwari/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow, multidict, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 datasets-1.18.3 dill-0.3.4 frozenlist-1.3.0 multidict-6.0.2 multiprocess-0.70.12.2 pyarrow-7.0.0 xxhash-3.0.0 yarl-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "38107a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "379f1f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__'],\n",
       "    num_rows: 6222\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = pd.read_csv('data/labeled_scouting.csv')\n",
    "test = pd.read_csv('data/augment/test.csv')\n",
    "train = pd.concat([labeled, test]).drop_duplicates(keep=False)\n",
    "\n",
    "custom_dataset_train = Dataset.from_pandas(train)\n",
    "custom_dataset_test = Dataset.from_pandas(test)\n",
    "custom_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6a2aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d38d4570-90b1-4cfe-b9d1-e1af157ab043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81053b003d9b4b80a454d808189024ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f912faa384884e07a684e4df369888ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = custom_dataset_train.map(lambda e: tokenizer(e['text'], truncation=True, padding=\"max_length\"), batched=True)\n",
    "train = train.remove_columns([\"text\", \"__index_level_0__\"])\n",
    "test = custom_dataset_test.map(lambda e: tokenizer(e['text'], truncation=True, padding=\"max_length\"), batched=True)\n",
    "test = test.remove_columns([\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef12a20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2711, 2003, 1037, 2504, 1015, 3348, 2504...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1996, 3029, 2031, 3734, 2711, 3807, 1010...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2772, 2005, 2019, 2682, 1011, 10453, 100...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2009, 2411, 3138, 2051, 2005, 2216, 2152...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2772, 2005, 2019, 2682, 1011, 10453, 100...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2711, 2275, 1037, 5785, 2501, 2007, 2403...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2711, 2275, 1996, 2711, 2501, 2005, 1316...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>0</td>\n",
       "      <td>[101, 2004, 1037, 13758, 1010, 1999, 2286, 101...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 2178, 9824, 1999, 1996, 3029, 14655, 101...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>1</td>\n",
       "      <td>[101, 1037, 2095, 2044, 4285, 3313, 1011, 1037...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          input_ids  \\\n",
       "0         0  [101, 2711, 2003, 1037, 2504, 1015, 3348, 2504...   \n",
       "1         1  [101, 1996, 3029, 2031, 3734, 2711, 3807, 1010...   \n",
       "2         1  [101, 2772, 2005, 2019, 2682, 1011, 10453, 100...   \n",
       "3         1  [101, 2009, 2411, 3138, 2051, 2005, 2216, 2152...   \n",
       "4         1  [101, 2772, 2005, 2019, 2682, 1011, 10453, 100...   \n",
       "...     ...                                                ...   \n",
       "6217      0  [101, 2711, 2275, 1037, 5785, 2501, 2007, 2403...   \n",
       "6218      0  [101, 2711, 2275, 1996, 2711, 2501, 2005, 1316...   \n",
       "6219      0  [101, 2004, 1037, 13758, 1010, 1999, 2286, 101...   \n",
       "6220      1  [101, 2178, 9824, 1999, 1996, 3029, 14655, 101...   \n",
       "6221      1  [101, 1037, 2095, 2044, 4285, 3313, 1011, 1037...   \n",
       "\n",
       "                                         token_type_ids  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "...                                                 ...   \n",
       "6217  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6218  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6219  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6220  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6221  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                         attention_mask  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "...                                                 ...  \n",
       "6217  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6218  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6219  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6220  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "6221  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[6222 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52ac27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(row1, row2, label=1, l=0.5):\n",
    "    mixed = list(map(int, l * np.array(row1['input_ids'].iloc[0]) + (1 - l) * np.array(row2['input_ids'].iloc[0])))\n",
    "    if sum(row1['attention_mask'].iloc[0]) > sum(row2['attention_mask'].iloc[0]):\n",
    "        new_attention = row1['attention_mask'].iloc[0]\n",
    "    else:\n",
    "        new_attention = row2['attention_mask'].iloc[0]\n",
    "\n",
    "    return pd.DataFrame([{\n",
    "        'label': label,\n",
    "        'input_ids': mixed,\n",
    "        'token_type_ids': row1['token_type_ids'].iloc[0],\n",
    "        'attention_mask': new_attention\n",
    "    }])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09123131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                          input_ids  \\\n",
      "0      1  [101, 2353, 1021, 1030, 1769, 9493, 4293, 2047...   \n",
      "\n",
      "                                      token_type_ids  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                      attention_mask  \n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n"
     ]
    }
   ],
   "source": [
    "tokenized_train = pd.DataFrame(train)\n",
    "pos = tokenized_train[tokenized_train[\"label\"] == 1].copy(deep=True)\n",
    "neg = tokenized_train[tokenized_train[\"label\"] == 0].copy(deep=True)\n",
    "for i in range(len(neg) - len(pos)):\n",
    "    row1 = pos.sample()\n",
    "    row2 = pos.sample()\n",
    "    new_embed = mixup(row1, row2)\n",
    "    tokenized_train = tokenized_train.append(new_embed, ignore_index=True)\n",
    "shuffle(tokenized_train)\n",
    "tokenized_train = Dataset.from_pandas(tokenized_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7990c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "arguments = TrainingArguments(\n",
    "    output_dir=\"sample_SD_trainer\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    evaluation_strategy=\"epoch\", # run validation at the end of each epoch\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=224\n",
    ")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Called at the end of validation. Gives accuracy\"\"\"\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # calculates the accuracy\n",
    "    return {\"accuracy\": np.mean(predictions == labels)}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test, # change to test when you do your final evaluation!\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10b45110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback, EarlyStoppingCallback\n",
    "\n",
    "class LoggingCallback(TrainerCallback):\n",
    "    def __init__(self, log_path):\n",
    "        self.log_path = log_path\n",
    "        \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            with open(self.log_path, \"a\") as f:\n",
    "                f.write(json.dumps(logs) + \"\\n\")\n",
    "\n",
    "\n",
    "trainer.add_callback(EarlyStoppingCallback(early_stopping_patience=1, early_stopping_threshold=0.0))\n",
    "trainer.add_callback(LoggingCallback(\"sample_SD_trainer/log.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b29cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amolsingh/anaconda3/envs/local_nmt/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 6222\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='1167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  19/1167 3:57:32 < 267:20:46, 0.00 it/s, Epoch 0.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c08c24",
   "metadata": {},
   "source": [
    "From_Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dc27f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load our saved model, we can pass the path to the checkpoint into the `from_pretrained` method:\n",
    "test_str = \"I enjoyed the movie!\"\n",
    "\n",
    "finetuned_model = AutoModelForSequenceClassification.from_pretrained(\"sample_SD_trainer/checkpoint-24\")\n",
    "model_inputs = tokenizer(test_str, return_tensors=\"pt\")\n",
    "prediction = torch.argmax(finetuned_model(**model_inputs).logits)\n",
    "print([\"NEGATIVE\", \"POSITIVE\"][prediction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
